import sqlite3
from datetime import datetime, timedelta
import threading
from queue import Queue
import json
import logging
import time
import requests
from typing import List, Dict
import os
from tenacity import retry, stop_after_attempt, wait_exponential

class BatchVulnerabilityChecker:
    def __init__(self, cache_file=None):
        """Initialize the vulnerability checker with caching"""
        # Set up logging first
        self.logger = logging.getLogger(__name__)
        self.logger.setLevel(logging.INFO)
        if not self.logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
            handler.setFormatter(formatter)
            self.logger.addHandler(handler)
            
        # Use OS-agnostic path for cache file
        if cache_file is None:
            cache_file = os.path.join(
                os.path.expanduser('~'),
                '.nodeheim',
                'vuln_cache.db'
            )
            os.makedirs(os.path.dirname(cache_file), exist_ok=True)
        
        self.cache_file = cache_file
        self.base_url = "https://services.nvd.nist.gov/rest/json/cves/2.0"
        self.queue = Queue()
        self.results = {}
        self.worker_count = 3  # Default worker count
        
        # Initialize cache
        self.init_cache()
        
        self.cache = {}
        self.cache_timeout = 3600  # 1 hour cache timeout
        
    def init_cache(self):
        """Initialize SQLite cache"""
        try:
            with sqlite3.connect(self.cache_file) as conn:
                conn.execute("""
                    CREATE TABLE IF NOT EXISTS vulnerability_cache (
                        product TEXT,
                        version TEXT,
                        data JSON,
                        timestamp DATETIME,
                        PRIMARY KEY (product, version)
                    )
                """)
                self.logger.info(f"Initialized vulnerability cache at {self.cache_file}")
        except Exception as e:
            self.logger.error(f"Error initializing cache: {e}")
            raise
    
    def get_cached_vulns(self, product: str, version: str) -> dict:
        """Get vulnerabilities from cache if fresh"""
        try:
            with sqlite3.connect(self.cache_file) as conn:
                result = conn.execute("""
                    SELECT data, timestamp FROM vulnerability_cache 
                    WHERE product = ? AND version = ?
                """, (product, version)).fetchone()
                
                if result:
                    data, timestamp = result
                    cache_date = datetime.fromisoformat(timestamp)
                    # Cache valid for 7 days
                    if datetime.now() - cache_date < timedelta(days=7):
                        self.logger.debug(f"Cache hit for {product} {version}")
                        return json.loads(data)
                self.logger.debug(f"Cache miss for {product} {version}")
                return None
        except Exception as e:
            self.logger.error(f"Error reading from cache: {e}")
            return None

    def cache_vulns(self, product: str, version: str, data: dict):
        """Cache vulnerability data"""
        try:
            with sqlite3.connect(self.cache_file) as conn:
                conn.execute("""
                    INSERT OR REPLACE INTO vulnerability_cache (product, version, data, timestamp)
                    VALUES (?, ?, ?, ?)
                """, (product, version, json.dumps(data), datetime.now().isoformat()))
                self.logger.debug(f"Cached vulnerability data for {product} {version}")
        except Exception as e:
            self.logger.error(f"Error caching vulnerability data: {e}")

    def _worker(self):
        """Worker thread to process vulnerability lookups"""
        while True:
            try:
                product, version = self.queue.get()
                if product == "STOP":
                    break
                    
                # Check cache first
                cached_data = self.get_cached_vulns(product, version)
                if cached_data:
                    self.results[(product, version)] = cached_data
                    self.queue.task_done()
                    continue
                
                # Make API request with rate limiting
                time.sleep(0.6)  # Rate limit to ~100 requests/minute
                self.logger.info(f"Requesting vulnerabilities for {product} {version}")
                
                response = requests.get(
                    self.base_url,
                    params={
                        'keywordSearch': f"{product} {version}",
                        'resultsPerPage': 50  # Limit results to most relevant
                    },
                    headers={
                        'User-Agent': 'NodeheimSecurityScanner/1.0'
                    },
                    timeout=10
                )
                
                if response.status_code == 200:
                    data = self._process_vulnerability_data(response.json(), product, version)
                    self.cache_vulns(product, version, data)
                    self.results[(product, version)] = data
                else:
                    self.logger.error(f"API request failed: {response.status_code}")
                
                self.queue.task_done()
                
            except Exception as e:
                self.logger.error(f"Error in vulnerability worker: {e}")
                self.queue.task_done()

    def _process_vulnerability_data(self, raw_data: dict, product: str, version: str) -> dict:
        """Process raw vulnerability data"""
        try:
            vulns = raw_data.get('vulnerabilities', [])
            processed_vulns = []
            
            for vuln in vulns:
                cve_data = vuln.get('cve', {})
                metrics = cve_data.get('metrics', {}).get('cvssMetricV31', [{}])[0]
                
                # Get the most relevant description
                descriptions = cve_data.get('descriptions', [])
                description = next(
                    (d['value'] for d in descriptions if d.get('lang') == 'en'),
                    descriptions[0].get('value') if descriptions else 'No description available'
                )
                
                processed_vulns.append({
                    'cve_id': cve_data.get('id', ''),
                    'description': description,
                    'cvss_score': metrics.get('cvssData', {}).get('baseScore', 0),
                    'severity': metrics.get('cvssData', {}).get('baseSeverity', 'UNKNOWN'),
                    'attack_vector': metrics.get('cvssData', {}).get('attackVector', 'UNKNOWN'),
                    'attack_complexity': metrics.get('cvssData', {}).get('attackComplexity', 'UNKNOWN'),
                    'impact_score': metrics.get('impactScore', 0)
                })
            
            return {
                'product': product,
                'version': version,
                'vulnerability_count': len(processed_vulns),
                'vulnerabilities': sorted(processed_vulns, key=lambda x: x['cvss_score'], reverse=True),
                'max_cvss_score': max([v['cvss_score'] for v in processed_vulns], default=0),
                'last_updated': datetime.now().isoformat()
            }
            
        except Exception as e:
            self.logger.error(f"Error processing vulnerability data: {e}")
            return {
                'product': product,
                'version': version,
                'vulnerability_count': 0,
                'vulnerabilities': [],
                'max_cvss_score': 0,
                'error': str(e)
            }

    def batch_check_services(self, services: List[Dict], timeout: int = 30) -> Dict:
        """Check vulnerabilities for multiple services"""
        results = {}
        for service in services:
            try:
                product = service.get('product', '')
                version = service.get('version', '')
                if product:
                    key = (product, version)
                    # Check cache first
                    if key in self.cache:
                        cache_time, cache_data = self.cache[key]
                        if time.time() - cache_time < self.cache_timeout:
                            results[key] = cache_data
                            continue
                            
                    # If not in cache or expired, check vulnerabilities
                    vulns = self.check_vulnerabilities(product, version, timeout)
                    results[key] = {
                        'vulnerabilities': vulns,
                        'total': len(vulns),
                        'ip_address': service.get('ip_address', service.get('host', ''))
                    }
                    # Update cache
                    self.cache[key] = (time.time(), results[key])
            except Exception as e:
                self.logger.error(f"Error checking vulnerabilities for {service}: {e}")
        return results

    def check_vulnerabilities(self, product: str, version: str, timeout: int) -> List[Dict]:
        """Check vulnerabilities for a specific product and version"""
        start_time = time.time()
        try:
            self.logger.info(f"Starting vulnerability check for {product} {version}")
            
            # Check cache first
            cached_data = self.get_cached_vulns(product, version)
            if cached_data:
                return cached_data.get('vulnerabilities', [])
            
            # Make API request
            response = requests.get(
                self.base_url,
                params={
                    'keywordSearch': f"{product} {version}",
                    'resultsPerPage': 50
                },
                headers={
                    'User-Agent': 'NodeheimSecurityScanner/1.0'
                },
                timeout=timeout
            )
            
            if response.status_code == 200:
                data = response.json()
                processed_data = self._process_vulnerability_data(data, product, version)
                vulns = processed_data.get('vulnerabilities', [])
                
                # Cache the results
                self.cache_vulns(product, version, processed_data)
                
                elapsed = time.time() - start_time
                self.logger.info(f"Completed vulnerability check in {elapsed:.2f} seconds")
                return vulns
            else:
                self.logger.error(f"API request failed with status code: {response.status_code}")
                return []
                
        except Exception as e:
            elapsed = time.time() - start_time
            self.logger.error(f"Vulnerability check failed after {elapsed:.2f} seconds: {e}")
            return []